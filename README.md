# üß† NLP Guidebook

Welcome to the **NLP Guidebook**! This educational repo provides a hands-on journey through the fundamentals of **Natural Language Processing** using Python, Jupyter Notebooks, and modern NLP libraries.

Whether you're just getting started or brushing up on your NLP skills, this guidebook walks you through key NLP topics, from theory to implementation, helping you understand how machines process human language.

üß≠ **Pipeline Overview**:  
Text Input ‚û°Ô∏è Preprocessing ‚û°Ô∏è Tokenization ‚û°Ô∏è Feature Engineering ‚û°Ô∏è Modeling ‚û°Ô∏è Evaluation

### ‚úÖ What You‚Äôll Learn

- A practical understanding of essential NLP tasks and preprocessing steps.
- Ability to build, clean, and process custom text corpora.
- Familiarity with libraries like NLTK, SpaCy, and Scikit-learn.
- Hands-on experience training NLP models from scratch.
- Exposure to both classical machine learning and deep learning NLP approaches.

> To simplify setup, the entire project runs inside a Docker container with JupyterLab ‚Äî no manual installs or Python environments required.

---

### üê≥ Quickstart: Run with Docker

Run the full environment with just one command.

#### ‚úÖ Prerequisites

- <a href="https://app.docker.com/signup" target="_blank">Create a free account </a>.
- <a href="https://www.docker.com/get-started/" target="_blank">Install Docker Desktop</a> and ensure it's running.
- Clone the repository:

```bash
git clone https://github.com/dfranco-projects/NLP_Guidebook.git && cd NLP_Guidebook
```

#### üöÄ Launch the guidebook environment:

```bash
docker-compose up -d
```

Then open your browser and navigate to:

<a href="http://localhost:8888/lab" target="_blank">http://localhost:8888/lab</a>

> Everything runs in Docker ‚Äî no setup headaches.

---

### üìö NLP Guidebook Structure

The project is organized as a series of Jupyter Notebooks, each aligned with an NLP concept:

1. **00 - NLP Intro**: High-level NLP overview and pipeline theory.
2. **01 - Corpus Webscraping**: Gathering legal, structured web text.
3. **02 - Corpus Cleaning**: Text cleaning (HTML tags, noise removal) and normalization.
4. **03 - Tokenization**: Segmenting text into sentences or words.
5. **04 - Text Preprocessing**: Stopword removal, stemming, and lemmatization.
6. **05 - Feature Engineering**: Representing text numerically (TF-IDF, embeddings, n-grams).
7. **06 - Modeling**: Classical ML models (Naive Bayes, SVM) for text tasks.
8. **07 - Advanced NLP Models**: Deep learning models (LSTMs, Transformers, BERT).
9. **08 - Applications**: Real-world case studies like chatbots, summarization, or classification.

---

### üìò Topics Covered

- **Text Data Manipulation**: Working with raw and structured text data in Python.
- **Tokenization**: Segmenting text into sentences, words, or characters.
- **Stemming and Lemmatization**: Reducing words to their root forms.
- **Text Classification**: Training ML models to categorize text (e.g., spam detection, sentiment).
- **Part-of-Speech Tagging**: Identifying grammatical roles of words in a sentence.
- **Web Scraping**: Extracting text data from websites for analysis.
- **Word Embeddings**: Representing words as vectors (Word2Vec, GloVe).
- **Sentiment Analysis**: Inferring emotional tone from textual data.
- **Structured Text Representations**: Transforming text into tables for ML models.

---

### üì¨ Contact

Feel free to explore the notebooks, run the examples, and adapt them to your projects.
If you have any questions or suggestions, reach out:

- [daniel.franco.inbox@gmail.com](mailto:daniel.franco.inbox@gmail.com)  
- <a href="https://www.linkedin.com/in/daniel-abrantes-franco/" target="_blank">LinkedIn</a>

---

Hope you find it useful! üöÄ
